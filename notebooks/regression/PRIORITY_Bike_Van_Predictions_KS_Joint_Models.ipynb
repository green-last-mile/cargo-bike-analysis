{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de7a545",
   "metadata": {},
   "source": [
    "# Regression @ Training at delivery level, testing at hexagon level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2887ff4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T17:49:45.185910Z",
     "iopub.status.busy": "2023-11-21T17:49:45.185533Z",
     "iopub.status.idle": "2023-11-21T17:49:46.162211Z",
     "shell.execute_reply": "2023-11-21T17:49:46.161633Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "# add the\n",
    "ROOT = os.path.join(Path(os.getcwd()), \"cargo-bike-analysis\")\n",
    "\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "from src.config import CargoBikeConfig, load_config\n",
    "from src.osm_tags import build_tag_filter\n",
    "from urban_tools.hex_pipeline import RouteHexHandler, TestTrainManager\n",
    "\n",
    "\n",
    "import polars as pl\n",
    "import geopolars as gpl\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5708e493",
   "metadata": {},
   "source": [
    "## Load Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd4d087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T17:49:46.164783Z",
     "iopub.status.busy": "2023-11-21T17:49:46.164543Z",
     "iopub.status.idle": "2023-11-21T17:49:46.201817Z",
     "shell.execute_reply": "2023-11-21T17:49:46.201336Z"
    }
   },
   "outputs": [],
   "source": [
    "config = load_config(ROOT + \"/config\" + \"/paper.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15730ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T17:49:46.203765Z",
     "iopub.status.busy": "2023-11-21T17:49:46.203421Z",
     "iopub.status.idle": "2023-11-21T17:49:46.477402Z",
     "shell.execute_reply": "2023-11-21T17:49:46.476853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>is_city</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892a339a5afffff</th>\n",
       "      <td>POLYGON ((-71.13572 42.23376, -71.13794 42.232...</td>\n",
       "      <td>True</td>\n",
       "      <td>Boston, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a3066a3bffff</th>\n",
       "      <td>POLYGON ((-71.08114 42.30902, -71.08337 42.308...</td>\n",
       "      <td>True</td>\n",
       "      <td>Boston, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a302a567ffff</th>\n",
       "      <td>POLYGON ((-70.82381 42.36269, -70.82604 42.361...</td>\n",
       "      <td>True</td>\n",
       "      <td>Boston, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a3066e17ffff</th>\n",
       "      <td>POLYGON ((-71.06072 42.33323, -71.06295 42.332...</td>\n",
       "      <td>True</td>\n",
       "      <td>Boston, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a3066b3bffff</th>\n",
       "      <td>POLYGON ((-71.06614 42.29023, -71.06837 42.289...</td>\n",
       "      <td>True</td>\n",
       "      <td>Boston, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          geometry  is_city  \\\n",
       "region_id                                                                     \n",
       "892a339a5afffff  POLYGON ((-71.13572 42.23376, -71.13794 42.232...     True   \n",
       "892a3066a3bffff  POLYGON ((-71.08114 42.30902, -71.08337 42.308...     True   \n",
       "892a302a567ffff  POLYGON ((-70.82381 42.36269, -70.82604 42.361...     True   \n",
       "892a3066e17ffff  POLYGON ((-71.06072 42.33323, -71.06295 42.332...     True   \n",
       "892a3066b3bffff  POLYGON ((-71.06614 42.29023, -71.06837 42.289...     True   \n",
       "\n",
       "                        city  \n",
       "region_id                     \n",
       "892a339a5afffff  Boston, USA  \n",
       "892a3066a3bffff  Boston, USA  \n",
       "892a302a567ffff  Boston, USA  \n",
       "892a3066e17ffff  Boston, USA  \n",
       "892a3066b3bffff  Boston, USA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h3_df = pd.concat(\n",
    "    [gpd.read_parquet(city.h3_file).assign(city=city.name) for city in config.Cities],\n",
    "    axis=0,\n",
    ").query(\"is_city\")\n",
    "\n",
    "h3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716c256b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T17:49:46.479446Z",
     "iopub.status.busy": "2023-11-21T17:49:46.479268Z",
     "iopub.status.idle": "2023-11-21T17:49:46.639030Z",
     "shell.execute_reply": "2023-11-21T17:49:46.638124Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load the Service Time Data\n",
    "\n",
    "delivery_df = pl.concat(\n",
    "    [\n",
    "        pl.read_parquet(city.file).select(\n",
    "            [\"h3\", pl.col(city.service_time_col).alias(\"service_time\")]\n",
    "        )\n",
    "        for city in config.ServiceTime\n",
    "    ],\n",
    ")\n",
    "\n",
    "# this does two things, one adds the city label and 2, it crops to the city limits\n",
    "service_time_df = delivery_df.join(\n",
    "    pl.DataFrame(h3_df.reset_index()[[\"region_id\", \"city\"]]),\n",
    "    left_on=\"h3\",\n",
    "    right_on=\"region_id\",\n",
    "    how=\"inner\",\n",
    ").with_columns(\n",
    "    [\n",
    "        pl.col(\"service_time\").log().alias(\"service_time_log\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "service_time_df = service_time_df.with_columns(pl.count().over(\"h3\").alias(\"h3_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dcd871",
   "metadata": {},
   "source": [
    "## Load the Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17075eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T17:49:46.642063Z",
     "iopub.status.busy": "2023-11-21T17:49:46.641632Z",
     "iopub.status.idle": "2023-11-21T17:49:46.885151Z",
     "shell.execute_reply": "2023-11-21T17:49:46.884374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>region_id</th>\n",
       "      <th>service_time</th>\n",
       "      <th>city</th>\n",
       "      <th>service_time_log</th>\n",
       "      <th>h3_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.32002</td>\n",
       "      <td>-5.493441</td>\n",
       "      <td>5.661098</td>\n",
       "      <td>20.907742</td>\n",
       "      <td>27.271231</td>\n",
       "      <td>-51.597836</td>\n",
       "      <td>-10.332759</td>\n",
       "      <td>45.391235</td>\n",
       "      <td>11.334351</td>\n",
       "      <td>10.848624</td>\n",
       "      <td>...</td>\n",
       "      <td>9.81983</td>\n",
       "      <td>5.172642</td>\n",
       "      <td>-7.319407</td>\n",
       "      <td>4.488636</td>\n",
       "      <td>20.39122</td>\n",
       "      <td>891fa441b83ffff</td>\n",
       "      <td>197.78692</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>5.28719</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.380403</td>\n",
       "      <td>-6.508181</td>\n",
       "      <td>18.301435</td>\n",
       "      <td>32.224045</td>\n",
       "      <td>28.388454</td>\n",
       "      <td>-35.504196</td>\n",
       "      <td>-18.33882</td>\n",
       "      <td>45.910313</td>\n",
       "      <td>19.495548</td>\n",
       "      <td>10.839149</td>\n",
       "      <td>...</td>\n",
       "      <td>15.916649</td>\n",
       "      <td>-1.365356</td>\n",
       "      <td>-8.613139</td>\n",
       "      <td>1.902637</td>\n",
       "      <td>28.177177</td>\n",
       "      <td>891fa441b53ffff</td>\n",
       "      <td>116.54679</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>4.758293</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.001373</td>\n",
       "      <td>-4.152925</td>\n",
       "      <td>16.126925</td>\n",
       "      <td>32.863831</td>\n",
       "      <td>27.293434</td>\n",
       "      <td>-32.102943</td>\n",
       "      <td>-19.849827</td>\n",
       "      <td>43.94511</td>\n",
       "      <td>20.050192</td>\n",
       "      <td>7.394312</td>\n",
       "      <td>...</td>\n",
       "      <td>14.05009</td>\n",
       "      <td>0.481978</td>\n",
       "      <td>-9.877087</td>\n",
       "      <td>-1.062505</td>\n",
       "      <td>28.223278</td>\n",
       "      <td>891fa441a63ffff</td>\n",
       "      <td>315.802888</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>5.755118</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.019328</td>\n",
       "      <td>-2.320791</td>\n",
       "      <td>13.435673</td>\n",
       "      <td>29.301117</td>\n",
       "      <td>26.384064</td>\n",
       "      <td>-32.886482</td>\n",
       "      <td>-17.608721</td>\n",
       "      <td>41.663998</td>\n",
       "      <td>17.434343</td>\n",
       "      <td>4.269286</td>\n",
       "      <td>...</td>\n",
       "      <td>11.727448</td>\n",
       "      <td>1.323634</td>\n",
       "      <td>-7.122827</td>\n",
       "      <td>-0.356202</td>\n",
       "      <td>25.736353</td>\n",
       "      <td>891fa441a6fffff</td>\n",
       "      <td>272.461272</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>5.607496</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.49675</td>\n",
       "      <td>-6.633764</td>\n",
       "      <td>18.607834</td>\n",
       "      <td>38.7845</td>\n",
       "      <td>26.904194</td>\n",
       "      <td>-21.650276</td>\n",
       "      <td>-21.75276</td>\n",
       "      <td>40.748585</td>\n",
       "      <td>23.255447</td>\n",
       "      <td>2.466128</td>\n",
       "      <td>...</td>\n",
       "      <td>10.815602</td>\n",
       "      <td>3.508712</td>\n",
       "      <td>-9.7584</td>\n",
       "      <td>-1.407086</td>\n",
       "      <td>28.712811</td>\n",
       "      <td>891fa44f4d7ffff</td>\n",
       "      <td>184.225706</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>5.216162</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1          2          3          4          5          6  \\\n",
       "0   -5.32002 -5.493441   5.661098  20.907742  27.271231 -51.597836 -10.332759   \n",
       "1  -8.380403 -6.508181  18.301435  32.224045  28.388454 -35.504196  -18.33882   \n",
       "2 -10.001373 -4.152925  16.126925  32.863831  27.293434 -32.102943 -19.849827   \n",
       "3  -9.019328 -2.320791  13.435673  29.301117  26.384064 -32.886482 -17.608721   \n",
       "4   -6.49675 -6.633764  18.607834    38.7845  26.904194 -21.650276  -21.75276   \n",
       "\n",
       "           7          8          9  ...         45        46        47  \\\n",
       "0  45.391235  11.334351  10.848624  ...    9.81983  5.172642 -7.319407   \n",
       "1  45.910313  19.495548  10.839149  ...  15.916649 -1.365356 -8.613139   \n",
       "2   43.94511  20.050192   7.394312  ...   14.05009  0.481978 -9.877087   \n",
       "3  41.663998  17.434343   4.269286  ...  11.727448  1.323634 -7.122827   \n",
       "4  40.748585  23.255447   2.466128  ...  10.815602  3.508712   -9.7584   \n",
       "\n",
       "         48         49        region_id service_time               city  \\\n",
       "0  4.488636   20.39122  891fa441b83ffff    197.78692  Brussels, Belgium   \n",
       "1  1.902637  28.177177  891fa441b53ffff    116.54679  Brussels, Belgium   \n",
       "2 -1.062505  28.223278  891fa441a63ffff   315.802888  Brussels, Belgium   \n",
       "3 -0.356202  25.736353  891fa441a6fffff   272.461272  Brussels, Belgium   \n",
       "4 -1.407086  28.712811  891fa44f4d7ffff   184.225706  Brussels, Belgium   \n",
       "\n",
       "  service_time_log h3_count  \n",
       "0          5.28719      201  \n",
       "1         4.758293      187  \n",
       "2         5.755118       10  \n",
       "3         5.607496       10  \n",
       "4         5.216162       24  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df = pl.read_parquet(config.GeoVex.embedding_file)\n",
    "\n",
    "embedding_df = embedding_df.join(\n",
    "    service_time_df, left_on=\"region_id\", right_on=\"h3\", how=\"inner\"\n",
    ")\n",
    "embedding_df = pd.DataFrame(embedding_df, columns=embedding_df.columns)\n",
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8594925d",
   "metadata": {},
   "source": [
    "## Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fbdc3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T17:49:46.887571Z",
     "iopub.status.busy": "2023-11-21T17:49:46.887352Z",
     "iopub.status.idle": "2023-11-21T17:49:47.429889Z",
     "shell.execute_reply": "2023-11-21T17:49:47.429094Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "from typing import Union\n",
    "from mapie.subsample import Subsample\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "from ngboost.learners import default_tree_learner, default_linear_learner\n",
    "from ngboost.scores import CRPS, MLE\n",
    "from ngboost.distns import LogNormal, Normal\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from mapie.metrics import regression_coverage_score\n",
    "from mapie.regression import MapieRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "from scipy.stats import spearmanr\n",
    "import CRPS.CRPS as pscore\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab00ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(\n",
    "    df,\n",
    "    feature_cols,\n",
    "    target_col,\n",
    "    train_regions: List[str] = None,\n",
    "    test_regions: List[str] = None,\n",
    "    test_size=0.2,\n",
    "):\n",
    "    unique_regions = df[\"region_id\"].unique()\n",
    "    # split the unique regions into train and test\n",
    "    if train_regions is None and test_regions is None:\n",
    "        train_regions, test_regions = train_test_split(\n",
    "            unique_regions, test_size=test_size\n",
    "        )\n",
    "\n",
    "    train_df = df[df[\"region_id\"].isin(train_regions)].copy()\n",
    "\n",
    "    #     test_df = (\n",
    "    #         df[df[\"region_id\"].isin(test_regions)]\n",
    "    #         .groupby(\"region_id\")\n",
    "    #         .agg({\n",
    "    #             f'{target_col}': \"median\",\n",
    "    #             **{col: \"first\" for col in feature_cols}\n",
    "    #         })\n",
    "    #         .reset_index()\n",
    "    #         .copy()\n",
    "    #     )\n",
    "\n",
    "    return train_df\n",
    "\n",
    "\n",
    "#     return train_df, test_df\n",
    "\n",
    "\n",
    "def rejection_sampling(i, Y_dists, y_lb, y_ub):\n",
    "    sample = Y_dists.sample(1)[0][i]\n",
    "    #     count = 0\n",
    "    while (sample < y_lb) or (sample > y_ub):\n",
    "        sample = Y_dists.sample(1)[0][i]\n",
    "    #         count+=1\n",
    "    #         if count==200:\n",
    "    #             return None\n",
    "    return sample\n",
    "\n",
    "\n",
    "def get_del_df(city, k=10):\n",
    "    city_df = embedding_df[embedding_df[\"city\"].str.contains(city)]\n",
    "    #     city_df = embedding_df[embedding_df['city'].isin(cities)]\n",
    "    return city_df[city_df[\"h3_count\"] >= k]\n",
    "\n",
    "\n",
    "def h3_aggregated_df(df):\n",
    "    return (\n",
    "        df.groupby(\"region_id\")\n",
    "        .agg({f\"{target_col}\": \"median\", **{col: \"first\" for col in feature_cols}})\n",
    "        .reset_index()\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_empirical_pnts(alpha, del_h3_df):\n",
    "    # 90th Percentile\n",
    "    def lower_quantile(x):\n",
    "        return x.quantile(alpha)\n",
    "\n",
    "    # 90th Percentile\n",
    "    def upper_quantile(x):\n",
    "        return x.quantile(1 - alpha)\n",
    "\n",
    "    del_h3_df.set_index(\"h3\", inplace=True)\n",
    "    h3_df = del_h3_df.groupby(\"h3\").agg(\n",
    "        {\"service_time\": [lower_quantile, \"median\", upper_quantile]}\n",
    "    )\n",
    "    h3_df.columns = list(map(\"_\".join, h3_df.columns.values))\n",
    "\n",
    "    # Collect Empirical points\n",
    "    s = del_h3_df.groupby(\"h3\").apply(lambda x: x[\"service_time\"].values)\n",
    "    empirical_pts_df = pd.merge(\n",
    "        h3_df, s.rename(\"empirical_pts\"), left_index=True, right_index=True\n",
    "    )\n",
    "    return empirical_pts_df\n",
    "\n",
    "\n",
    "def get_test_scores(df):\n",
    "    (\n",
    "        median_r2s,\n",
    "        median_rmses,\n",
    "        median_KS_scores,\n",
    "        median_pinball_scores,\n",
    "        CRPS_median_RS_scores,\n",
    "    ) = ([], [], [], [], [])\n",
    "    y_pred_lb, y_pred_ub = (\n",
    "        df[\"service_time_lower_quantile_rj_pred\"],\n",
    "        df[\"service_time_upper_quantile_rj_pred\"],\n",
    "    )\n",
    "\n",
    "    cov_score = np.round(\n",
    "        regression_coverage_score(\n",
    "            df[\"service_time_median_rj_pred\"].values, y_pred_lb, y_pred_ub\n",
    "        ),\n",
    "        3,\n",
    "    )\n",
    "    avg_width = np.round((y_pred_ub - y_pred_lb).mean(), 3)\n",
    "    upp_quan_r2 = np.round(\n",
    "        r2_score(df[\"service_time_upper_quantile_true\"].values, y_pred_ub), 3\n",
    "    )\n",
    "    upp_quan_rmse = np.round(\n",
    "        mean_squared_error(\n",
    "            df[\"service_time_upper_quantile_true\"].values, y_pred_ub, squared=False\n",
    "        ),\n",
    "        3,\n",
    "    )\n",
    "\n",
    "    for hx in df.itertuples():\n",
    "        temp, pemp = getattr(hx, \"empirical_pts_true\"), getattr(\n",
    "            hx, \"empirical_pts_rj_pred\"\n",
    "        )\n",
    "        median_r2s.append(np.round(r2_score(temp, pemp), 3))\n",
    "        median_rmses.append(np.round(mean_squared_error(temp, pemp, squared=False), 3))\n",
    "        median_KS_scores.append(stats.ks_2samp(temp, pemp))\n",
    "        median_pinball_scores.append(mean_pinball_loss(temp, pemp))\n",
    "    #         CRPS_median_RS_scores.append(pscore(pemp,getattr(hx,'service_time_median_rj_pred')).compute())\n",
    "\n",
    "    return (\n",
    "        cov_score,\n",
    "        avg_width,\n",
    "        upp_quan_r2,\n",
    "        upp_quan_rmse,\n",
    "        np.mean(np.array(median_r2s)),\n",
    "        np.mean(np.array(median_rmses)),\n",
    "        np.mean(np.array(median_KS_scores)),\n",
    "        np.mean(np.array(median_pinball_scores)),\n",
    "    )\n",
    "\n",
    "\n",
    "#     return cov_score, avg_width, upp_quan_r2, upp_quan_rmse, np.mean(np.array(median_r2s)), np.mean(np.array(median_rmses)), np.mean(np.array(median_KS_scores)), np.mean(np.array(median_pinball_scores)), np.mean(CRPS_median_RS_scores, axis=0).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24d371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Nice test\n",
    "# df=get_del_df('Boston, USA', 20)\n",
    "# df = df.rename(columns={'region_id':'h3'})\n",
    "# f=get_empirical_pnts(alpha, df)\n",
    "# # g=f.copy()\n",
    "# f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa53ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify the feature and target columns\n",
    "feature_cols, target_col = list(map(str, range(50))), \"service_time_log\"\n",
    "\n",
    "\n",
    "# ------------------- Loop over cities and cross validation folds -------------------\n",
    "def retrieve_the_cv_splits(cities, n_splits):\n",
    "    # Cross Validation Folds\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "\n",
    "    city_sets = {}\n",
    "    city_sets[\"train\"] = {}\n",
    "    #     city_sets['test'] = {}\n",
    "    for i in range(n_splits):\n",
    "        city_sets[\"train\"][f\"split_{i}\"] = pd.DataFrame()\n",
    "\n",
    "    for city in cities:\n",
    "        #         city_sets['test'][city] = {}\n",
    "\n",
    "        # get the city dataframe\n",
    "        city_df = get_del_df(city, 20)\n",
    "\n",
    "        # get the unique regions\n",
    "        unique_regions = city_df[\"region_id\"].unique().tolist()\n",
    "\n",
    "        for i, (train_index, val_index) in enumerate(kf.split(unique_regions)):\n",
    "            train_regions = [unique_regions[i] for i in train_index]\n",
    "            val_regions = [unique_regions[i] for i in val_index]\n",
    "            train_df = split_test_train(\n",
    "                city_df,\n",
    "                feature_cols,\n",
    "                target_col,\n",
    "                train_regions=train_regions,\n",
    "                test_regions=val_regions,\n",
    "            )\n",
    "\n",
    "            if not city_sets[\"train\"][f\"split_{i}\"].empty:\n",
    "                city_sets[\"train\"][f\"split_{i}\"] = city_sets[\"train\"][\n",
    "                    f\"split_{i}\"\n",
    "                ].append(train_df)\n",
    "            else:\n",
    "                city_sets[\"train\"][f\"split_{i}\"] = train_df\n",
    "\n",
    "    #             city_sets['test'][city][f'split_{i}'] = test_df\n",
    "\n",
    "    return city_sets\n",
    "\n",
    "\n",
    "def get_predictions_entirety(ngb, mapie, df, alpha=alpha):\n",
    "    region_ids = df[\"region_id\"].to_list()\n",
    "    _, tmp = mapie.predict(df[feature_cols].to_numpy(), alpha=[alpha, 0.5])\n",
    "    Y_dists = ngb.pred_dist(df[feature_cols].to_numpy())\n",
    "    y_pred, y_pis = tmp[:, 1, 0].ravel(), tmp[:, :, 1]\n",
    "    lower_quan = y_pis[:, 0].ravel()\n",
    "    upper_quan = y_pis[:, 1].ravel()\n",
    "\n",
    "    # Go to the hexagonal level for predictions on quantiles here\n",
    "    # 1. First get true empirical points aggregated on hexes\n",
    "    # Rejection sampling\n",
    "    np.random.seed(42)\n",
    "    dlvry_rej_sample_service_time = [\n",
    "        np.exp(rejection_sampling(i, Y_dists, lower_quan[i], upper_quan[i]))\n",
    "        for i in range(y_pis.shape[0])\n",
    "    ]\n",
    "    df_with_h3_true_samples = pd.DataFrame(\n",
    "        {\"h3\": region_ids, \"service_time\": np.exp(df[target_col].astype(float))}\n",
    "    )\n",
    "    hex_empirical = get_empirical_pnts(alpha, df_with_h3_true_samples)\n",
    "\n",
    "    # 2. Now get rejection sampled predicted points aggregated on hexes\n",
    "    df_with_h3_rj_samples = pd.DataFrame(\n",
    "        {\"h3\": region_ids, \"service_time\": dlvry_rej_sample_service_time}\n",
    "    )\n",
    "    hex_pred_rj_samples_agg = get_empirical_pnts(alpha, df_with_h3_rj_samples)\n",
    "\n",
    "    # 3. Get the empirical points in one dataset\n",
    "    joint_h3_true_rj_pred_df = pd.merge(\n",
    "        hex_empirical,\n",
    "        hex_pred_rj_samples_agg,\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "        suffixes=(\"_true\", \"_rj_pred\"),\n",
    "    )\n",
    "    return joint_h3_true_rj_pred_df\n",
    "\n",
    "\n",
    "def get_preds_from_joint_model_city_wise(cities, pred_cities, alpha, n_splits):\n",
    "    scores = {}\n",
    "    predictions_df = {}\n",
    "    # Initialize dictionaries\n",
    "    for city in cities:\n",
    "        scores[city] = {}\n",
    "\n",
    "    city_sets = retrieve_the_cv_splits(cities, n_splits)\n",
    "\n",
    "    for pred_city in pred_cities:\n",
    "        #         cov_scores, avg_widths, median_r2s, median_rmses, upp_quan_r2s = [],[],[],[],[]\n",
    "        #         upp_quan_rmses, median_KS_scores, median_pinball_scores = [],[],[]\n",
    "        #         upp_quan_rmses, median_KS_scores, median_pinball_scores, CRPS_median_RS_scores = [],[],[],[]\n",
    "\n",
    "        for i in range(n_splits):\n",
    "            train_df = city_sets[\"train\"][f\"split_{i}\"]\n",
    "            # get the city dataframe\n",
    "            pred_city_df = get_del_df(pred_city, 20)\n",
    "            #             test_df = city_sets['test'][pred_city][f'split_{i}']\n",
    "            #             test_df = pred_city_df.groupby(\"region_id\").agg({\n",
    "            #                 f'{target_col}': \"median\",\n",
    "            #                 **{col: \"first\" for col in feature_cols}\n",
    "            #             }).reset_index().copy()\n",
    "\n",
    "            X_train, X_cal, y_train, y_cal = train_test_split(\n",
    "                train_df[feature_cols].to_numpy(),\n",
    "                train_df[target_col].to_numpy(),\n",
    "                test_size=0.2,\n",
    "                random_state=23,\n",
    "            )\n",
    "\n",
    "            ngb = NGBRegressor(\n",
    "                n_estimators=1,\n",
    "                learning_rate=1e-3,\n",
    "                Dist=Normal,\n",
    "                Base=default_tree_learner,\n",
    "                natural_gradient=True,\n",
    "                Score=MLE,\n",
    "                verbose=False,\n",
    "            )\n",
    "            mapie = MapieRegressor(ngb).fit(X_cal, y_cal)\n",
    "            mapie.fit(X_train, y_train)\n",
    "            ngb.fit(X_train, y_train)\n",
    "\n",
    "            predictions_df[pred_city] = get_predictions_entirety(\n",
    "                ngb, mapie, pred_city_df, alpha\n",
    "            )\n",
    "\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45a69e",
   "metadata": {},
   "source": [
    "## Joint Van Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b64fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "van_cities = [\"Boston, USA\", \"Seattle, USA\", \"Austin, USA\", \"Chicago, USA\"]\n",
    "bike_cities = [\"London, UK\", \"Brussels, Belgium\"]\n",
    "\n",
    "predictions_df = {}\n",
    "\n",
    "predictions_df[\"vans\"] = get_preds_from_joint_model_city_wise(\n",
    "    bike_cities, van_cities, alpha=alpha, n_splits=2\n",
    ")\n",
    "predictions_df[\"bikes\"] = get_preds_from_joint_model_city_wise(\n",
    "    van_cities, bike_cities, alpha=alpha, n_splits=2\n",
    ")\n",
    "\n",
    "# # Get predictions\n",
    "# van_scores = get_preds_from_joint_model_city_wise(van_cities, van_cities, alpha=alpha, n_splits=5)\n",
    "\n",
    "import json, pickle\n",
    "\n",
    "# Path to the saved JSON file\n",
    "# score_file_path = f\"{os.environ['HOME']}/CQR_Experiments/Van_joint_model_CV_KS_SCORES_NGB.json\"\n",
    "pred_file_path = (\n",
    "    f\"{os.environ['HOME']}/CQR_Experiments/DF_joint_model_CV_KS_predictions_NGB.pickle\"\n",
    ")\n",
    "\n",
    "# # the json file where the output must be stored\n",
    "# out_file = open(score_file_path, \"w\")\n",
    "\n",
    "# json.dump(van_scores, out_file, indent = 6)\n",
    "# out_file.close()\n",
    "\n",
    "# Store data (serialize)\n",
    "with open(pred_file_path, \"wb\") as handle:\n",
    "    pickle.dump(predictions_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load data (deserialize)\n",
    "with open(pred_file_path, \"rb\") as handle:\n",
    "    predictions_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919e653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_time_lower_quantile_true</th>\n",
       "      <th>service_time_median_true</th>\n",
       "      <th>service_time_upper_quantile_true</th>\n",
       "      <th>empirical_pts_true</th>\n",
       "      <th>service_time_lower_quantile_rj_pred</th>\n",
       "      <th>service_time_median_rj_pred</th>\n",
       "      <th>service_time_upper_quantile_rj_pred</th>\n",
       "      <th>empirical_pts_rj_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892a30640b7ffff</th>\n",
       "      <td>20.000</td>\n",
       "      <td>153.5</td>\n",
       "      <td>418.710</td>\n",
       "      <td>[156.99999999999994, 110.99999999999997, 218.1...</td>\n",
       "      <td>103.288167</td>\n",
       "      <td>139.410674</td>\n",
       "      <td>192.176375</td>\n",
       "      <td>[113.09576661431475, 126.87290342967748, 146.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a3064103ffff</th>\n",
       "      <td>40.150</td>\n",
       "      <td>147.5</td>\n",
       "      <td>517.090</td>\n",
       "      <td>[464.09999999999997, 129.99999999999997, 85.00...</td>\n",
       "      <td>96.385137</td>\n",
       "      <td>128.203761</td>\n",
       "      <td>196.521651</td>\n",
       "      <td>[113.62879843518037, 108.19469882470183, 198.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a3064107ffff</th>\n",
       "      <td>40.000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>535.000</td>\n",
       "      <td>[654.5000000000002, 40.0, 70.00000000000003, 2...</td>\n",
       "      <td>97.091020</td>\n",
       "      <td>134.381308</td>\n",
       "      <td>179.534020</td>\n",
       "      <td>[103.28654508906489, 126.36018729890343, 149.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a306410bffff</th>\n",
       "      <td>53.595</td>\n",
       "      <td>106.0</td>\n",
       "      <td>474.600</td>\n",
       "      <td>[149.99999999999997, 85.00000000000001, 74.999...</td>\n",
       "      <td>94.948332</td>\n",
       "      <td>127.603993</td>\n",
       "      <td>190.919405</td>\n",
       "      <td>[95.24575520659074, 118.38285949150924, 166.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892a306410fffff</th>\n",
       "      <td>32.750</td>\n",
       "      <td>94.0</td>\n",
       "      <td>490.275</td>\n",
       "      <td>[104.99999999999997, 175.99999999999991, 214.9...</td>\n",
       "      <td>102.444977</td>\n",
       "      <td>150.543405</td>\n",
       "      <td>187.502256</td>\n",
       "      <td>[122.04071667712383, 100.01081525871068, 129.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 service_time_lower_quantile_true  service_time_median_true  \\\n",
       "h3                                                                            \n",
       "892a30640b7ffff                            20.000                     153.5   \n",
       "892a3064103ffff                            40.150                     147.5   \n",
       "892a3064107ffff                            40.000                     108.0   \n",
       "892a306410bffff                            53.595                     106.0   \n",
       "892a306410fffff                            32.750                      94.0   \n",
       "\n",
       "                 service_time_upper_quantile_true  \\\n",
       "h3                                                  \n",
       "892a30640b7ffff                           418.710   \n",
       "892a3064103ffff                           517.090   \n",
       "892a3064107ffff                           535.000   \n",
       "892a306410bffff                           474.600   \n",
       "892a306410fffff                           490.275   \n",
       "\n",
       "                                                empirical_pts_true  \\\n",
       "h3                                                                   \n",
       "892a30640b7ffff  [156.99999999999994, 110.99999999999997, 218.1...   \n",
       "892a3064103ffff  [464.09999999999997, 129.99999999999997, 85.00...   \n",
       "892a3064107ffff  [654.5000000000002, 40.0, 70.00000000000003, 2...   \n",
       "892a306410bffff  [149.99999999999997, 85.00000000000001, 74.999...   \n",
       "892a306410fffff  [104.99999999999997, 175.99999999999991, 214.9...   \n",
       "\n",
       "                 service_time_lower_quantile_rj_pred  \\\n",
       "h3                                                     \n",
       "892a30640b7ffff                           103.288167   \n",
       "892a3064103ffff                            96.385137   \n",
       "892a3064107ffff                            97.091020   \n",
       "892a306410bffff                            94.948332   \n",
       "892a306410fffff                           102.444977   \n",
       "\n",
       "                 service_time_median_rj_pred  \\\n",
       "h3                                             \n",
       "892a30640b7ffff                   139.410674   \n",
       "892a3064103ffff                   128.203761   \n",
       "892a3064107ffff                   134.381308   \n",
       "892a306410bffff                   127.603993   \n",
       "892a306410fffff                   150.543405   \n",
       "\n",
       "                 service_time_upper_quantile_rj_pred  \\\n",
       "h3                                                     \n",
       "892a30640b7ffff                           192.176375   \n",
       "892a3064103ffff                           196.521651   \n",
       "892a3064107ffff                           179.534020   \n",
       "892a306410bffff                           190.919405   \n",
       "892a306410fffff                           187.502256   \n",
       "\n",
       "                                             empirical_pts_rj_pred  \n",
       "h3                                                                  \n",
       "892a30640b7ffff  [113.09576661431475, 126.87290342967748, 146.3...  \n",
       "892a3064103ffff  [113.62879843518037, 108.19469882470183, 198.6...  \n",
       "892a3064107ffff  [103.28654508906489, 126.36018729890343, 149.7...  \n",
       "892a306410bffff  [95.24575520659074, 118.38285949150924, 166.96...  \n",
       "892a306410fffff  [122.04071667712383, 100.01081525871068, 129.1...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"vans\"][\"Boston, USA\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c9801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
